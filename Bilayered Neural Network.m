function [trainedClassifier, validationAccuracy] = trainClassifier(trainingData)
% [trainedClassifier, validationAccuracy] = trainClassifier(trainingData)
% Returns a trained classifier and its accuracy. This code recreates the
% classification model trained in Classification Learner app. Use the
% generated code to automate training the same model with new data, or to
% learn how to programmatically train models.
%
%  Input:
%      trainingData: A table containing the same predictor and response
%       columns as those imported into the app.
%
%  Output:
%      trainedClassifier: A struct containing the trained classifier. The
%       struct contains various fields with information about the trained
%       classifier.
%
%      trainedClassifier.predictFcn: A function to make predictions on new
%       data.
%
%      validationAccuracy: A double containing the accuracy as a
%       percentage. In the app, the Models pane displays this overall
%       accuracy score for each model.
%
% Use the code to train the model with new data. To retrain your
% classifier, call the function from the command line with your original
% data or new data as the input argument trainingData.
%
% For example, to retrain a classifier trained with the original data set
% T, enter:
%   [trainedClassifier, validationAccuracy] = trainClassifier(T)
%
% To make predictions with the returned 'trainedClassifier' on new data T2,
% use
%   yfit = trainedClassifier.predictFcn(T2)
%
% T2 must be a table containing at least the same predictor columns as used
% during training. For details, enter:
%   trainedClassifier.HowToPredict

% Auto-generated by MATLAB on 11-Jun-2022 10:15:22


% Extract predictors and response
% This code processes the data into the right shape for training the
% model.
inputTable = trainingData;
predictorNames = {'data1', 'data2', 'data3', 'data4', 'data5', 'data6', 'data7', 'data8', 'data9', 'data10', 'data11', 'data12', 'data13', 'data14', 'data15', 'data16', 'data17', 'data18', 'data19', 'data20', 'data21', 'data22', 'data23', 'data24', 'data25', 'data26', 'data27', 'data28', 'data29', 'data30', 'data31', 'data32', 'data33', 'data34', 'data35', 'data36', 'data37', 'data38', 'data39', 'data40', 'data41', 'data42', 'data43', 'data44', 'data45', 'data46', 'data47', 'data48', 'data49', 'data50', 'data51', 'data52', 'data53', 'data54', 'data55', 'data56', 'data57', 'data58', 'data59', 'data60', 'data61', 'data62', 'data63', 'data64', 'data65', 'data66', 'data67', 'data68', 'data69', 'data70', 'data71', 'data72', 'data73', 'data74', 'data75', 'data76', 'data77', 'data78', 'data79', 'data80', 'data81', 'data82', 'data83', 'data84', 'data85', 'data86', 'data87', 'data88', 'data89', 'data90', 'data91', 'data92', 'data93', 'data94', 'data95', 'data96', 'data97', 'data98', 'data99', 'data100', 'data101', 'data102', 'data103', 'data104', 'data105', 'data106', 'data107', 'data108', 'data109', 'data110', 'data111', 'data112', 'data113', 'data114', 'data115', 'data116', 'data117', 'data118', 'data119', 'data120', 'data121', 'data122', 'data123', 'data124', 'data125', 'data126', 'data127', 'data128', 'data129', 'data130', 'data131', 'data132', 'data133', 'data134', 'data135', 'data136', 'data137', 'data138', 'data139', 'data140', 'data141', 'data142', 'data143', 'data144', 'data145', 'data146', 'data147', 'data148', 'data149', 'data150', 'data151', 'data152', 'data153', 'data154', 'data155', 'data156', 'data157', 'data158', 'data159', 'data160', 'data161', 'data162', 'data163', 'data164', 'data165', 'data166', 'data167', 'data168', 'data169', 'data170', 'data171', 'data172', 'data173', 'data174', 'data175', 'data176', 'data177', 'data178', 'data179', 'data180', 'data181', 'data182', 'data183', 'data184', 'data185', 'data186', 'data187', 'data188', 'data189', 'data190', 'data191', 'data192', 'data193', 'data194', 'data195', 'data196', 'data197', 'data198', 'data199', 'data200', 'data201', 'data202', 'data203', 'data204', 'data205', 'data206', 'data207', 'data208', 'data209', 'data210', 'data211', 'data212', 'data213', 'data214', 'data215', 'data216', 'data217', 'data218', 'data219', 'data220', 'data221', 'data222', 'data223', 'data224', 'data225', 'data226', 'data227', 'data228', 'data229', 'data230', 'data231', 'data232', 'data233', 'data234', 'data235', 'data236', 'data237', 'data238', 'data239', 'data240', 'data241', 'data242', 'data243', 'data244', 'data245', 'data246', 'data247', 'data248', 'data249', 'data250', 'data251', 'data252', 'data253', 'data254', 'data255', 'data256', 'data257', 'data258', 'data259', 'data260', 'data261', 'data262', 'data263', 'data264', 'data265', 'data266', 'data267', 'data268', 'data269', 'data270', 'data271', 'data272', 'data273', 'data274', 'data275', 'data276', 'data277', 'data278', 'data279', 'data280', 'data281', 'data282', 'data283', 'data284', 'data285', 'data286', 'data287', 'data288', 'data289', 'data290', 'data291', 'data292', 'data293', 'data294', 'data295', 'data296', 'data297', 'data298', 'data299', 'data300', 'data301', 'data302', 'data303', 'data304', 'data305', 'data306', 'data307', 'data308', 'data309', 'data310', 'data311', 'data312', 'data313', 'data314', 'data315', 'data316', 'data317', 'data318', 'data319', 'data320', 'data321', 'data322', 'data323', 'data324', 'data325', 'data326', 'data327', 'data328', 'data329', 'data330', 'data331', 'data332', 'data333', 'data334', 'data335', 'data336', 'data337', 'data338', 'data339', 'data340', 'data341', 'data342', 'data343', 'data344', 'data345', 'data346', 'data347', 'data348', 'data349', 'data350', 'data351', 'data352', 'data353', 'data354', 'data355', 'data356', 'data357', 'data358', 'data359', 'data360', 'data361', 'data362', 'data363', 'data364', 'data365', 'data366', 'data367', 'data368', 'data369', 'data370', 'data371', 'data372', 'data373', 'data374', 'data375', 'data376', 'data377', 'data378', 'data379', 'data380', 'data381', 'data382', 'data383', 'data384'};
predictors = inputTable(:, predictorNames);
response = inputTable.class;
isCategoricalPredictor = [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false];

% Train a classifier
% This code specifies all the classifier options and trains the classifier.
classificationNeuralNetwork = fitcnet(...
    predictors, ...
    response, ...
    'LayerSizes', [10 10], ...
    'Activations', 'relu', ...
    'Lambda', 0, ...
    'IterationLimit', 1000, ...
    'Standardize', true, ...
    'ClassNames', categorical({'asleep'; 'awake'}));

% Create the result struct with predict function
predictorExtractionFcn = @(t) t(:, predictorNames);
neuralNetworkPredictFcn = @(x) predict(classificationNeuralNetwork, x);
trainedClassifier.predictFcn = @(x) neuralNetworkPredictFcn(predictorExtractionFcn(x));

% Add additional fields to the result struct
trainedClassifier.RequiredVariables = {'data1', 'data10', 'data100', 'data101', 'data102', 'data103', 'data104', 'data105', 'data106', 'data107', 'data108', 'data109', 'data11', 'data110', 'data111', 'data112', 'data113', 'data114', 'data115', 'data116', 'data117', 'data118', 'data119', 'data12', 'data120', 'data121', 'data122', 'data123', 'data124', 'data125', 'data126', 'data127', 'data128', 'data129', 'data13', 'data130', 'data131', 'data132', 'data133', 'data134', 'data135', 'data136', 'data137', 'data138', 'data139', 'data14', 'data140', 'data141', 'data142', 'data143', 'data144', 'data145', 'data146', 'data147', 'data148', 'data149', 'data15', 'data150', 'data151', 'data152', 'data153', 'data154', 'data155', 'data156', 'data157', 'data158', 'data159', 'data16', 'data160', 'data161', 'data162', 'data163', 'data164', 'data165', 'data166', 'data167', 'data168', 'data169', 'data17', 'data170', 'data171', 'data172', 'data173', 'data174', 'data175', 'data176', 'data177', 'data178', 'data179', 'data18', 'data180', 'data181', 'data182', 'data183', 'data184', 'data185', 'data186', 'data187', 'data188', 'data189', 'data19', 'data190', 'data191', 'data192', 'data193', 'data194', 'data195', 'data196', 'data197', 'data198', 'data199', 'data2', 'data20', 'data200', 'data201', 'data202', 'data203', 'data204', 'data205', 'data206', 'data207', 'data208', 'data209', 'data21', 'data210', 'data211', 'data212', 'data213', 'data214', 'data215', 'data216', 'data217', 'data218', 'data219', 'data22', 'data220', 'data221', 'data222', 'data223', 'data224', 'data225', 'data226', 'data227', 'data228', 'data229', 'data23', 'data230', 'data231', 'data232', 'data233', 'data234', 'data235', 'data236', 'data237', 'data238', 'data239', 'data24', 'data240', 'data241', 'data242', 'data243', 'data244', 'data245', 'data246', 'data247', 'data248', 'data249', 'data25', 'data250', 'data251', 'data252', 'data253', 'data254', 'data255', 'data256', 'data257', 'data258', 'data259', 'data26', 'data260', 'data261', 'data262', 'data263', 'data264', 'data265', 'data266', 'data267', 'data268', 'data269', 'data27', 'data270', 'data271', 'data272', 'data273', 'data274', 'data275', 'data276', 'data277', 'data278', 'data279', 'data28', 'data280', 'data281', 'data282', 'data283', 'data284', 'data285', 'data286', 'data287', 'data288', 'data289', 'data29', 'data290', 'data291', 'data292', 'data293', 'data294', 'data295', 'data296', 'data297', 'data298', 'data299', 'data3', 'data30', 'data300', 'data301', 'data302', 'data303', 'data304', 'data305', 'data306', 'data307', 'data308', 'data309', 'data31', 'data310', 'data311', 'data312', 'data313', 'data314', 'data315', 'data316', 'data317', 'data318', 'data319', 'data32', 'data320', 'data321', 'data322', 'data323', 'data324', 'data325', 'data326', 'data327', 'data328', 'data329', 'data33', 'data330', 'data331', 'data332', 'data333', 'data334', 'data335', 'data336', 'data337', 'data338', 'data339', 'data34', 'data340', 'data341', 'data342', 'data343', 'data344', 'data345', 'data346', 'data347', 'data348', 'data349', 'data35', 'data350', 'data351', 'data352', 'data353', 'data354', 'data355', 'data356', 'data357', 'data358', 'data359', 'data36', 'data360', 'data361', 'data362', 'data363', 'data364', 'data365', 'data366', 'data367', 'data368', 'data369', 'data37', 'data370', 'data371', 'data372', 'data373', 'data374', 'data375', 'data376', 'data377', 'data378', 'data379', 'data38', 'data380', 'data381', 'data382', 'data383', 'data384', 'data39', 'data4', 'data40', 'data41', 'data42', 'data43', 'data44', 'data45', 'data46', 'data47', 'data48', 'data49', 'data5', 'data50', 'data51', 'data52', 'data53', 'data54', 'data55', 'data56', 'data57', 'data58', 'data59', 'data6', 'data60', 'data61', 'data62', 'data63', 'data64', 'data65', 'data66', 'data67', 'data68', 'data69', 'data7', 'data70', 'data71', 'data72', 'data73', 'data74', 'data75', 'data76', 'data77', 'data78', 'data79', 'data8', 'data80', 'data81', 'data82', 'data83', 'data84', 'data85', 'data86', 'data87', 'data88', 'data89', 'data9', 'data90', 'data91', 'data92', 'data93', 'data94', 'data95', 'data96', 'data97', 'data98', 'data99'};
trainedClassifier.ClassificationNeuralNetwork = classificationNeuralNetwork;
trainedClassifier.About = 'This struct is a trained model exported from Classification Learner R2022a.';
trainedClassifier.HowToPredict = sprintf('To make predictions on a new table, T, use: \n  yfit = c.predictFcn(T) \nreplacing ''c'' with the name of the variable that is this struct, e.g. ''trainedModel''. \n \nThe table, T, must contain the variables returned by: \n  c.RequiredVariables \nVariable formats (e.g. matrix/vector, datatype) must match the original training data. \nAdditional variables are ignored. \n \nFor more information, see <a href="matlab:helpview(fullfile(docroot, ''stats'', ''stats.map''), ''appclassification_exportmodeltoworkspace'')">How to predict using an exported model</a>.');

% Extract predictors and response
% This code processes the data into the right shape for training the
% model.
inputTable = trainingData;
predictorNames = {'data1', 'data2', 'data3', 'data4', 'data5', 'data6', 'data7', 'data8', 'data9', 'data10', 'data11', 'data12', 'data13', 'data14', 'data15', 'data16', 'data17', 'data18', 'data19', 'data20', 'data21', 'data22', 'data23', 'data24', 'data25', 'data26', 'data27', 'data28', 'data29', 'data30', 'data31', 'data32', 'data33', 'data34', 'data35', 'data36', 'data37', 'data38', 'data39', 'data40', 'data41', 'data42', 'data43', 'data44', 'data45', 'data46', 'data47', 'data48', 'data49', 'data50', 'data51', 'data52', 'data53', 'data54', 'data55', 'data56', 'data57', 'data58', 'data59', 'data60', 'data61', 'data62', 'data63', 'data64', 'data65', 'data66', 'data67', 'data68', 'data69', 'data70', 'data71', 'data72', 'data73', 'data74', 'data75', 'data76', 'data77', 'data78', 'data79', 'data80', 'data81', 'data82', 'data83', 'data84', 'data85', 'data86', 'data87', 'data88', 'data89', 'data90', 'data91', 'data92', 'data93', 'data94', 'data95', 'data96', 'data97', 'data98', 'data99', 'data100', 'data101', 'data102', 'data103', 'data104', 'data105', 'data106', 'data107', 'data108', 'data109', 'data110', 'data111', 'data112', 'data113', 'data114', 'data115', 'data116', 'data117', 'data118', 'data119', 'data120', 'data121', 'data122', 'data123', 'data124', 'data125', 'data126', 'data127', 'data128', 'data129', 'data130', 'data131', 'data132', 'data133', 'data134', 'data135', 'data136', 'data137', 'data138', 'data139', 'data140', 'data141', 'data142', 'data143', 'data144', 'data145', 'data146', 'data147', 'data148', 'data149', 'data150', 'data151', 'data152', 'data153', 'data154', 'data155', 'data156', 'data157', 'data158', 'data159', 'data160', 'data161', 'data162', 'data163', 'data164', 'data165', 'data166', 'data167', 'data168', 'data169', 'data170', 'data171', 'data172', 'data173', 'data174', 'data175', 'data176', 'data177', 'data178', 'data179', 'data180', 'data181', 'data182', 'data183', 'data184', 'data185', 'data186', 'data187', 'data188', 'data189', 'data190', 'data191', 'data192', 'data193', 'data194', 'data195', 'data196', 'data197', 'data198', 'data199', 'data200', 'data201', 'data202', 'data203', 'data204', 'data205', 'data206', 'data207', 'data208', 'data209', 'data210', 'data211', 'data212', 'data213', 'data214', 'data215', 'data216', 'data217', 'data218', 'data219', 'data220', 'data221', 'data222', 'data223', 'data224', 'data225', 'data226', 'data227', 'data228', 'data229', 'data230', 'data231', 'data232', 'data233', 'data234', 'data235', 'data236', 'data237', 'data238', 'data239', 'data240', 'data241', 'data242', 'data243', 'data244', 'data245', 'data246', 'data247', 'data248', 'data249', 'data250', 'data251', 'data252', 'data253', 'data254', 'data255', 'data256', 'data257', 'data258', 'data259', 'data260', 'data261', 'data262', 'data263', 'data264', 'data265', 'data266', 'data267', 'data268', 'data269', 'data270', 'data271', 'data272', 'data273', 'data274', 'data275', 'data276', 'data277', 'data278', 'data279', 'data280', 'data281', 'data282', 'data283', 'data284', 'data285', 'data286', 'data287', 'data288', 'data289', 'data290', 'data291', 'data292', 'data293', 'data294', 'data295', 'data296', 'data297', 'data298', 'data299', 'data300', 'data301', 'data302', 'data303', 'data304', 'data305', 'data306', 'data307', 'data308', 'data309', 'data310', 'data311', 'data312', 'data313', 'data314', 'data315', 'data316', 'data317', 'data318', 'data319', 'data320', 'data321', 'data322', 'data323', 'data324', 'data325', 'data326', 'data327', 'data328', 'data329', 'data330', 'data331', 'data332', 'data333', 'data334', 'data335', 'data336', 'data337', 'data338', 'data339', 'data340', 'data341', 'data342', 'data343', 'data344', 'data345', 'data346', 'data347', 'data348', 'data349', 'data350', 'data351', 'data352', 'data353', 'data354', 'data355', 'data356', 'data357', 'data358', 'data359', 'data360', 'data361', 'data362', 'data363', 'data364', 'data365', 'data366', 'data367', 'data368', 'data369', 'data370', 'data371', 'data372', 'data373', 'data374', 'data375', 'data376', 'data377', 'data378', 'data379', 'data380', 'data381', 'data382', 'data383', 'data384'};
predictors = inputTable(:, predictorNames);
response = inputTable.class;
isCategoricalPredictor = [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false];

% Perform cross-validation
partitionedModel = crossval(trainedClassifier.ClassificationNeuralNetwork, 'KFold', 10);

% Compute validation predictions
[validationPredictions, validationScores] = kfoldPredict(partitionedModel);

% Compute validation accuracy
validationAccuracy = 1 - kfoldLoss(partitionedModel, 'LossFun', 'ClassifError');
